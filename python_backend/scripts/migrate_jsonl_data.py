#!/usr/bin/env python3
"""
è³‡æ–™é·ç§»è…³æœ¬ï¼šå°‡èˆŠæ ¼å¼çš„ JSONL æª”æ¡ˆè½‰æ›ç‚ºæ–°çš„çµ±ä¸€æ ¼å¼
"""

import os
import json
import time
from pathlib import Path
from typing import Dict, Any, List
import shutil
from datetime import datetime

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
import sys
sys.path.append(str(Path(__file__).parent.parent))

from app.models.arbitrage import ExecutionRecord, ExecutionLeg


def backup_file(file_path: str) -> str:
    """å‚™ä»½åŸå§‹æª”æ¡ˆ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"{file_path}.backup_{timestamp}"
    shutil.copy2(file_path, backup_path)
    print(f"âœ… å·²å‚™ä»½åŸå§‹æª”æ¡ˆ: {backup_path}")
    return backup_path


def migrate_execution_record(old_record: Dict[str, Any]) -> Dict[str, Any]:
    """å°‡èˆŠæ ¼å¼çš„åŸ·è¡Œè¨˜éŒ„è½‰æ›ç‚ºæ–°æ ¼å¼"""
    try:
        # å»ºç«‹æ–°æ ¼å¼çš„åŸ·è¡Œè¨˜éŒ„
        new_record = ExecutionRecord(
            ts=old_record.get("ts", int(time.time() * 1000)),
            pairId=old_record.get("pairId", "unknown"),
            qty=float(old_record.get("qty", 0.001)),
            status=old_record.get("status", "success"),
            maxExecs=int(old_record.get("maxExecs", 1)),
            totalTriggers=int(old_record.get("totalTriggers", 1)),
            leg1=ExecutionLeg(
                exchange=old_record.get("leg1", {}).get("exchange", "bybit"),
                symbol=old_record.get("leg1", {}).get("symbol", "BTCUSDT"),
                type=old_record.get("leg1", {}).get("type", "spot"),
                side=old_record.get("leg1", {}).get("side", "buy"),
                orderId=old_record.get("leg1", {}).get("orderId")
            ),
            leg2=ExecutionLeg(
                exchange=old_record.get("leg2", {}).get("exchange", "bybit"),
                symbol=old_record.get("leg2", {}).get("symbol", "BTCUSDT"),
                type=old_record.get("leg2", {}).get("type", "spot"),
                side=old_record.get("leg2", {}).get("side", "sell"),
                orderId=old_record.get("leg2", {}).get("orderId")
            ),
            # å‘å¾Œå…¼å®¹æ¬„ä½
            success=old_record.get("success"),
            reason=old_record.get("reason"),
            error=old_record.get("error")
        )
        
        # è½‰æ›ç‚ºå­—å…¸æ ¼å¼ï¼ˆä½¿ç”¨ aliasï¼‰
        return new_record.dict(by_alias=True)
        
    except Exception as e:
        print(f"âŒ è½‰æ›è¨˜éŒ„å¤±æ•—: {e}")
        print(f"   åŸå§‹è¨˜éŒ„: {old_record}")
        return old_record  # ä¿ç•™åŸå§‹è¨˜éŒ„


def migrate_jsonl_file(file_path: str) -> bool:
    """é·ç§»å–®å€‹ JSONL æª”æ¡ˆ"""
    if not os.path.exists(file_path):
        print(f"âš ï¸  æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        return False
    
    print(f"ğŸ”„ é–‹å§‹é·ç§»æª”æ¡ˆ: {file_path}")
    
    # å‚™ä»½åŸå§‹æª”æ¡ˆ
    backup_path = backup_file(file_path)
    
    try:
        # è®€å–åŸå§‹è³‡æ–™
        original_records = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    record = json.loads(line)
                    original_records.append(record)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  ç¬¬ {line_num} è¡Œ JSON è§£æå¤±æ•—: {e}")
                    continue
        
        print(f"ğŸ“Š è®€å–åˆ° {len(original_records)} ç­†è¨˜éŒ„")
        
        # è½‰æ›è³‡æ–™
        migrated_records = []
        for i, record in enumerate(original_records):
            migrated_record = migrate_execution_record(record)
            migrated_records.append(migrated_record)
            
            if (i + 1) % 100 == 0:
                print(f"   å·²è™•ç† {i + 1}/{len(original_records)} ç­†è¨˜éŒ„")
        
        # å¯«å…¥æ–°æ ¼å¼æª”æ¡ˆ
        with open(file_path, 'w', encoding='utf-8') as f:
            for record in migrated_records:
                f.write(json.dumps(record, ensure_ascii=False) + '\n')
        
        print(f"âœ… é·ç§»å®Œæˆ: {len(migrated_records)} ç­†è¨˜éŒ„")
        return True
        
    except Exception as e:
        print(f"âŒ é·ç§»å¤±æ•—: {e}")
        # æ¢å¾©å‚™ä»½
        shutil.copy2(backup_path, file_path)
        print(f"ğŸ”„ å·²æ¢å¾©åŸå§‹æª”æ¡ˆ")
        return False


def find_jsonl_files(data_dir: str) -> List[str]:
    """å°‹æ‰¾æ‰€æœ‰ JSONL æª”æ¡ˆ"""
    jsonl_files = []
    data_path = Path(data_dir)
    
    if not data_path.exists():
        print(f"âš ï¸  è³‡æ–™ç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        return jsonl_files
    
    # å°‹æ‰¾ arbitrage ç›®éŒ„ä¸‹çš„ JSONL æª”æ¡ˆ
    arbitrage_dir = data_path / "arbitrage"
    if arbitrage_dir.exists():
        for file_path in arbitrage_dir.glob("*.jsonl"):
            jsonl_files.append(str(file_path))
    
    return jsonl_files


def validate_migrated_data(file_path: str) -> bool:
    """é©—è­‰é·ç§»å¾Œçš„è³‡æ–™æ ¼å¼"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    record = json.loads(line)
                    # å˜—è©¦ç”¨ Pydantic æ¨¡å‹é©—è­‰
                    ExecutionRecord(**record)
                except Exception as e:
                    print(f"âŒ ç¬¬ {line_num} è¡Œé©—è­‰å¤±æ•—: {e}")
                    return False
        
        print(f"âœ… è³‡æ–™æ ¼å¼é©—è­‰é€šé: {file_path}")
        return True
        
    except Exception as e:
        print(f"âŒ é©—è­‰éç¨‹å‡ºéŒ¯: {e}")
        return False


def main():
    """ä¸»è¦é·ç§»æµç¨‹"""
    print("ğŸš€ é–‹å§‹è³‡æ–™é·ç§»...")
    print("=" * 50)
    
    # ç¢ºå®šè³‡æ–™ç›®éŒ„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    data_dir = project_root / "data"
    
    print(f"ğŸ“ å°ˆæ¡ˆæ ¹ç›®éŒ„: {project_root}")
    print(f"ğŸ“ è³‡æ–™ç›®éŒ„: {data_dir}")
    
    # å°‹æ‰¾ JSONL æª”æ¡ˆ
    jsonl_files = find_jsonl_files(str(data_dir))
    
    if not jsonl_files:
        print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°éœ€è¦é·ç§»çš„ JSONL æª”æ¡ˆ")
        return
    
    print(f"ğŸ“‹ æ‰¾åˆ° {len(jsonl_files)} å€‹ JSONL æª”æ¡ˆ:")
    for file_path in jsonl_files:
        print(f"   - {file_path}")
    
    # ç¢ºèªæ˜¯å¦ç¹¼çºŒ
    response = input("\næ˜¯å¦ç¹¼çºŒé·ç§»ï¼Ÿ(y/N): ").strip().lower()
    if response != 'y':
        print("âŒ å–æ¶ˆé·ç§»")
        return
    
    # åŸ·è¡Œé·ç§»
    success_count = 0
    for file_path in jsonl_files:
        print(f"\n{'='*50}")
        if migrate_jsonl_file(file_path):
            # é©—è­‰é·ç§»çµæœ
            if validate_migrated_data(file_path):
                success_count += 1
            else:
                print(f"âš ï¸  æª”æ¡ˆé·ç§»æˆåŠŸä½†é©—è­‰å¤±æ•—: {file_path}")
        else:
            print(f"âŒ æª”æ¡ˆé·ç§»å¤±æ•—: {file_path}")
    
    # ç¸½çµ
    print(f"\n{'='*50}")
    print(f"ğŸ“Š é·ç§»ç¸½çµ:")
    print(f"   - ç¸½æª”æ¡ˆæ•¸: {len(jsonl_files)}")
    print(f"   - æˆåŠŸé·ç§»: {success_count}")
    print(f"   - å¤±æ•—æ•¸é‡: {len(jsonl_files) - success_count}")
    
    if success_count == len(jsonl_files):
        print("ğŸ‰ æ‰€æœ‰æª”æ¡ˆé·ç§»æˆåŠŸï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æª”æ¡ˆé·ç§»å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")


if __name__ == "__main__":
    main()
